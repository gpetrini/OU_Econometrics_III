#+TITLE: Problem Set 2 - Introduction to Optimization
#+AUTHOR: Gabriel Petrini, Prof. Tyler Ransom
#+DATE: September 8th 2020, 9:00 AM
#+PROPERTY: header-args: :results output :exports both :async t
#+PROPERTY: header-args:julia :tangle gps_PS2.jl
#+PROPERTY: header-args:julia :session *julia*


#+BEGIN_SRC julia
teste = "Teste"
#+END_SRC

#+RESULTS:

#+BEGIN_SRC julia :session *julia*
println(teste)
#+END_SRC
^[[200~using Random, Statistics,
^[[201~               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type "?" for help, "]?" for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.4.1
 _/ |\__'_|_|_|\__'_|  |  Ubuntu ⛬  julia/1.4.1+dfsg-1
|__/                   |

julia> using Random, Statistics

julia> using Random, Statistics, FreqTables

julia> using LinearAlgebra, Optim, GLM

julia> using DataFrames, CSV, HTTP

julia> f(x) = -x[1]^4-10x[1]^3-2x[1]^2-3x[1]-2
f (generic function with 1 method)

julia> minusf(x) = x[1]^4+10x[1]^3+2x[1]^2+3x[1]+2
minusf (generic function with 1 method)

julia> startval = rand(1)   # random starting value
1-element Array{Float64,1}:
 0.5157438955869367

julia> result = optimize(minusf, startval, BFGS())
Results of Optimization Algorithm
 * Algorithm: BFGS
 * Starting Point: [0.5157438955869367]
 * Minimizer: [-7.378243405528493]
 * Minimum: -9.643134e+02
 * Iterations: 5
 * Convergence: true
   * |x - x'| ≤ 0.0e+00: false 
     |x - x'| = 2.63e-05 
   * |f(x) - f(x')| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x')| = -7.68e-11 |f(x)|
   * |g(x)| ≤ 1.0e-08: true 
     |g(x)| = 3.82e-09 
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 19
 * Gradient Calls: 19

julia> url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2020/master/ProblemSets/PS1-julia-intro/nlsw88.csv"
"https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2020/master/ProblemSets/PS1-julia-intro/nlsw88.csv"

julia> df = CSV.read(HTTP.get(url).body)
┌ Warning: `CSV.read(input; kw...)` is deprecated in favor of `using DataFrames; CSV.read(input, DataFrame; kw...)
│   caller = read(::Array{UInt8,1}) at CSV.jl:40
└ @ CSV ~/.julia/packages/CSV/MKemC/src/CSV.jl:40
2246×17 DataFrame. Omitted printing of 3 columns
│ Row  │ idcode │ age   │ race  │ married │ never_married │ grade  │ collgrad │ south │ smsa  │ c_city │ industry │ occupation │ union   │ wage    │
│      │ Int64  │ Int64 │ Int64 │ Int64   │ Int64         │ Int64? │ Int64    │ Int64 │ Int64 │ Int64  │ Int64?   │ Int64?     │ Int64?  │ Float64 │
├──────┼────────┼───────┼───────┼─────────┼───────────────┼────────┼──────────┼───────┼───────┼────────┼──────────┼────────────┼─────────┼─────────┤
│ 1    │ 1      │ 37    │ 2     │ 0       │ 0             │ 12     │ 0        │ 0     │ 1     │ 0      │ 5        │ 6          │ 1       │ 11.7391 │
│ 2    │ 2      │ 37    │ 2     │ 0       │ 0             │ 12     │ 0        │ 0     │ 1     │ 1      │ 4        │ 5          │ 1       │ 6.40096 │
│ 3    │ 3      │ 42    │ 2     │ 0       │ 1             │ 12     │ 0        │ 0     │ 1     │ 1      │ 4        │ 3          │ missing │ 5.01672 │
│ 4    │ 4      │ 43    │ 1     │ 1       │ 0             │ 17     │ 1        │ 0     │ 1     │ 0      │ 11       │ 13         │ 1       │ 9.03381 │
⋮
│ 2242 │ 5153   │ 35    │ 1     │ 0       │ 1             │ 12     │ 0        │ 1     │ 1     │ 0      │ 11       │ 8          │ missing │ 5.51712 │
│ 2243 │ 5154   │ 44    │ 1     │ 1       │ 0             │ 16     │ 1        │ 1     │ 1     │ 0      │ 11       │ 1          │ 0       │ 14.3237 │
│ 2244 │ 5156   │ 42    │ 1     │ 1       │ 0             │ 12     │ 0        │ 1     │ 0     │ 0      │ 8        │ 3          │ 0       │ 3.82448 │
│ 2245 │ 5157   │ 38    │ 2     │ 1       │ 0             │ 12     │ 0        │ 1     │ 0     │ 0      │ 11       │ 8          │ 0       │ 2.44766 │
│ 2246 │ 5159   │ 43    │ 2     │ 0       │ 0             │ 12     │ 0        │ 1     │ 1     │ 1      │ 11       │ 3          │ 1       │ 7.15781 │

julia> X = [ones(size(df,1),1) df.age df.race.==1 df.collgrad.==1]
2246×4 Array{Float64,2}:
 1.0  37.0  0.0  0.0
 1.0  37.0  0.0  0.0
 1.0  42.0  0.0  0.0
 1.0  43.0  1.0  1.0
 1.0  42.0  1.0  0.0
 1.0  39.0  1.0  0.0
 ⋮               
 1.0  35.0  1.0  0.0
 1.0  35.0  1.0  0.0
 1.0  44.0  1.0  1.0
 1.0  42.0  1.0  0.0
 1.0  38.0  0.0  0.0
 1.0  43.0  0.0  0.0

julia> y = df.married.==1
2246-element BitArray{1}:
 0
 0
 0
 1
 1
 1
 ⋮
 1
 0
 1
 1
 1
 0

julia> ction ols(beta, X, y)
           ssr = (y.-X*beta)'*(y.-X*beta)
           return ssr
       end
       
ERROR: syntax: extra token "ols" after end of expression
Stacktrace:
 [1] top-level scope at REPL[12]:0

julia> function ols(beta, X, y)
           ssr = (y.-X*beta)'*(y.-X*beta)
           return ssr
       end
ols (generic function with 1 method)

julia> beta_hat_ols = optimize(b -> ols(b, X, y), rand(size(X,2)), LBFGS(), Optim.Options(g_tol=1e-6, iterations=100_000, show_trace=true))
Iter     Function value   Gradient norm 
     0     1.731944e+05     1.544509e+06
     1     1.029837e+03     7.387624e+02
     2     4.950887e+02     3.591872e+01
     3     4.936177e+02     6.704306e-01
     4     4.936093e+02     4.207830e+00
     5     4.936093e+02     1.220329e-07
Results of Optimization Algorithm
 * Algorithm: L-BFGS
 * Starting Point: [0.7078416552274884,0.19940939630536136, ...]
 * Minimizer: [0.6613509510269348,-0.004625908031434186, ...]
 * Minimum: 4.936093e+02
 * Iterations: 5
 * Convergence: true
   * |x - x'| ≤ 0.0e+00: false 
     |x - x'| = 3.94e-06 
   * |f(x) - f(x')| ≤ 0.0e+00 |f(x)|: false
     |f(x) - f(x')| = 2.59e-09 |f(x)|
   * |g(x)| ≤ 1.0e-06: true 
     |g(x)| = 1.22e-07 
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 22
 * Gradient Calls: 22

julia> println(beta_hat_ols.minimizer)
[0.6613509510269348, -0.004625908031434186, 0.22595043227989614, -0.012184197709204009]

julia> bols = inv(X'*X)*X'*y
4-element Array{Float64,1}:
  0.6613509511877042
 -0.004625908035375747
  0.22595043227530237
 -0.01218419772065558

julia> df.white = df.race.==1
2246-element BitArray{1}:
 0
 0
 0
 1
 1
 1
 ⋮
 1
 1
 1
 1
 0
 0

julia> bols_lm = lm(@formula(married ~ age + white + collgrad), df)
StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

married ~ 1 + age + white + collgrad

Coefficients:
─────────────────────────────────────────────────────────────────────────────
                   Coef.  Std. Error      t  Pr(>|t|)   Lower 95%   Upper 95%
─────────────────────────────────────────────────────────────────────────────
(Intercept)   0.661351    0.127491     5.19    <1e-6    0.411338   0.911364
age          -0.00462591  0.00324314  -1.43    0.1539  -0.0109858  0.00173397
white         0.22595     0.0223827   10.09    <1e-22   0.182057   0.269843
collgrad     -0.0121842   0.0233565   -0.52    0.6020  -0.0579868  0.0336184
─────────────────────────────────────────────────────────────────────────────

julia> df
2246×18 DataFrame. Omitted printing of 4 columns
│ Row  │ idcode │ age   │ race  │ married │ never_married │ grade  │ collgrad │ south │ smsa  │ c_city │ industry │ occupation │ union   │ wage    │
│      │ Int64  │ Int64 │ Int64 │ Int64   │ Int64         │ Int64? │ Int64    │ Int64 │ Int64 │ Int64  │ Int64?   │ Int64?     │ Int64?  │ Float64 │
├──────┼────────┼───────┼───────┼─────────┼───────────────┼────────┼──────────┼───────┼───────┼────────┼──────────┼────────────┼─────────┼─────────┤
│ 1    │ 1      │ 37    │ 2     │ 0       │ 0             │ 12     │ 0        │ 0     │ 1     │ 0      │ 5        │ 6          │ 1       │ 11.7391 │
│ 2    │ 2      │ 37    │ 2     │ 0       │ 0             │ 12     │ 0        │ 0     │ 1     │ 1      │ 4        │ 5          │ 1       │ 6.40096 │
│ 3    │ 3      │ 42    │ 2     │ 0       │ 1             │ 12     │ 0        │ 0     │ 1     │ 1      │ 4        │ 3          │ missing │ 5.01672 │
│ 4    │ 4      │ 43    │ 1     │ 1       │ 0             │ 17     │ 1        │ 0     │ 1     │ 0      │ 11       │ 13         │ 1       │ 9.03381 │
⋮
│ 2242 │ 5153   │ 35    │ 1     │ 0       │ 1             │ 12     │ 0        │ 1     │ 1     │ 0      │ 11       │ 8          │ missing │ 5.51712 │
│ 2243 │ 5154   │ 44    │ 1     │ 1       │ 0             │ 16     │ 1        │ 1     │ 1     │ 0      │ 11       │ 1          │ 0       │ 14.3237 │
│ 2244 │ 5156   │ 42    │ 1     │ 1       │ 0             │ 12     │ 0        │ 1     │ 0     │ 0      │ 8        │ 3          │ 0       │ 3.82448 │
│ 2245 │ 5157   │ 38    │ 2     │ 1       │ 0             │ 12     │ 0        │ 1     │ 0     │ 0      │ 11       │ 8          │ 0       │ 2.44766 │
│ 2246 │ 5159   │ 43    │ 2     │ 0       │ 0             │ 12     │ 0        │ 1     │ 1     │ 1      │ 11       │ 3          │ 1       │ 7.15781 │

julia> df.married==0
false

julia> df.married.==0
2246-element BitArray{1}:
 1
 1
 1
 0
 0
 0
 ⋮
 0
 1
 0
 0
 0
 1

julia> bols_lm = lm(@formula(married ~ age + white + collgrad), df)
StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

married ~ 1 + age + white + collgrad

Coefficients:
─────────────────────────────────────────────────────────────────────────────
                   Coef.  Std. Error      t  Pr(>|t|)   Lower 95%   Upper 95%
─────────────────────────────────────────────────────────────────────────────
(Intercept)   0.661351    0.127491     5.19    <1e-6    0.411338   0.911364
age          -0.00462591  0.00324314  -1.43    0.1539  -0.0109858  0.00173397
white         0.22595     0.0223827   10.09    <1e-22   0.182057   0.269843
collgrad     -0.0121842   0.0233565   -0.52    0.6020  -0.0579868  0.0336184
─────────────────────────────────────────────────────────────────────────────

julia> b_glm = glm(@formula(married ~ age + white + collgrad), df, Binomial(), LogitLink())
StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Array{Float64,1},Binomial{Float64},LogitLink},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

married ~ 1 + age + white + collgrad

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(>|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)   0.746554    0.578983    1.29    0.1973  -0.388231   1.88134
age          -0.0210778   0.0147497  -1.43    0.1530  -0.0499867  0.00783116
white         0.955807    0.0981953   9.73    <1e-21   0.763347   1.14827
collgrad     -0.055974    0.106218   -0.53    0.5982  -0.264157   0.152209
────────────────────────────────────────────────────────────────────────────

julia> b_glm = glm(@formula(married ~ age + white + collgrad), df, Binomial(), LogitLink()) |> println
StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Array{Float64,1},Binomial{Float64},LogitLink},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

married ~ 1 + age + white + collgrad

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(>|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)   0.746554    0.578983    1.29    0.1973  -0.388231   1.88134
age          -0.0210778   0.0147497  -1.43    0.1530  -0.0499867  0.00783116
white         0.955807    0.0981953   9.73    <1e-21   0.763347   1.14827
collgrad     -0.055974    0.106218   -0.53    0.5982  -0.264157   0.152209
────────────────────────────────────────────────────────────────────────────

julia> b_glm = glm(@formula(married ~ age + white + collgrad), df, Binomial(), LogitLink()) |> println("β_glm estimates:",_)
ERROR: syntax: all-underscore identifier used as rvalue
Stacktrace:
 [1] top-level scope at REPL[26]:1

julia> b_glm = glm(@formula(married ~ age + white + collgrad), df, Binomial(), LogitLink()) |> println("β_glm estimates:",)
β_glm estimates:
ERROR: MethodError: objects of type Nothing are not callable
Stacktrace:
 [1] |>(::StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Array{Float64,1},Binomial{Float64},LogitLink},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}, ::Nothing) at ./operators.jl:823
 [2] top-level scope at REPL[27]:1

julia> b_glm = glm(@formula(married ~ age + white + collgrad), df, Binomial(), LogitLink())
StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Array{Float64,1},Binomial{Float64},LogitLink},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

married ~ 1 + age + white + collgrad

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(>|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)   0.746554    0.578983    1.29    0.1973  -0.388231   1.88134
age          -0.0210778   0.0147497  -1.43    0.1530  -0.0499867  0.00783116
white         0.955807    0.0981953   9.73    <1e-21   0.763347   1.14827
collgrad     -0.055974    0.106218   -0.53    0.5982  -0.264157   0.152209
────────────────────────────────────────────────────────────────────────────

julia> println("β_glm estimates:", b_glm)
β_glm estimates:StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Array{Float64,1},Binomial{Float64},LogitLink},GLM.DensePredChol{Float64,Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}

married ~ 1 + age + white + collgrad

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      z  Pr(>|z|)   Lower 95%   Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)   0.746554    0.578983    1.29    0.1973  -0.388231   1.88134
age          -0.0210778   0.0147497  -1.43    0.1530  -0.0499867  0.00783116
white         0.955807    0.0981953   9.73    <1e-21   0.763347   1.14827
collgrad     -0.055974    0.106218   -0.53    0.5982  -0.264157   0.152209
────────────────────────────────────────────────────────────────────────────

julia> 
