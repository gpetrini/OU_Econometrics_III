#+TITLE: Structural modeling process
#+AUTHOR: Gabriel Petrini
#+DATE: September 1st, 2020
#+LATEX_HEADER: \bibliography{References.bib}
#+LATEX_HEADER: \usepackage{minted}

* Pre-class reading: Practical Issues in Structural Estimation ([[https://www.youtube.com/watch?v=0hazaPBAYWE][Keane YouTube talk, 2015]])

** Structural Model Development

Structural estimation has several key stages

*** Theoretical model development

Assume you want to build a structural model to address an *economic or policy question of interest*. A good starting point is to ask what elements your model must have to _credibly_ address the question:

- The model cannot be so simple (or stylized) that it essentially imposes _answers /a priori/_
  - You must include all the mechanisms that generates same relevant pattern in order to not rig the results to answer the question of interest
- It must be plausible to assume parameters of the model are *invariant* to policy experiments that you plan to do
  - You should plan what experiments will be employed with this model in the very beginning

=Example: ``How important is the moral hazard effect of health insurance?''=

*** Practical Specification issues

There is an inherent conflict between:

a) Model that is rich enough to credibly address the question of interest
   - As we make model richier, we tend to get more *state variables*
b) A model that is feasible to solve and estimate
   - Too many state variables makes solution infeaseble


The art of Structural Estimation is largely about how to develop ``rich'' models that are still feasible to solve and estimate. There are strategies to reduce the number of state variables (/e.g./ fertility and labor supply, brand inventories - assuming stationary tastes) so it is not necessarily to keep track of all states altogether.

*** Solving the model & Understanding how the model works


Let's assume you have settled on a model that you think is fit for purpose. These two steps should be done in tandem. You should be writing programs to _at the same time_:

- solve the model
- simulate the model
- calculate descriptive statistics

Always begin by programming a simple special case of the model - where theory makes a clear prediction of how it should behave. If your simulations do not lines up with basic theory, you have done something wrong.

- You should add mechanisms of features to the model _one at time_.
  - Always rig the program so if a parameter (let say, $\theta$) is set to zero, the new mechanism is shut down. Then, make sure you get the *Exact* same simulation results as before if you set this parameter to zero
- Once you have introduced a new mechanism, manipulate the new parameters related to that mechanism to see what they do
  - Make sure the simulation results make intuitive sense
    - If they do not make sense, you probably have a bug
    - _Sometimes_, basic intuition turns out to be wrong and you have learned some economics
- Continuing introducing new mechanisms step-by-step until you have your full model
- By the end of this process, you will have a good understanding of how each feature of the model (and the parameters) affects behaviour
  - Spending a lot of time learning what each parameter does to behaviour also gives you a good intuitive understanding of how the model is identified and could warn about identification issues

*** Estimation

Nonlinear estimation is difficult

- You cannot just start the parameter vector at some random place and expect it to coverage
  - *Suggestion:* Finds values that fits the intercepts
- You need to *calibrate* the model to achieve a half way decent fit before iterating
  - This also teaches you a lot of how the model works
  - You should expect that this calibration process will take a long time and lots of patience
- If you find it impossible to get a decent calibration _by hand_, it means:
  - there is some important mechanism you have omitted from the model
  - you do not really understand the model
  - you are not trying hard enough
- *Strategy:* Presents the simplest model version. Discuss why it does not fit the data and what is needed to achieve it.
- Now that you are ready to estimate you need to write the code for the parameter search algorithm
  - *Recommendation:* BHHH and Simplex (and help the search algorithm by hand)
  - Only build up gradually to the full model as you are sure everything is working properly
- Estimation is not a mechanical process
  - As the parameter iterate, you should look
    - Simulation of key statistics vs. actual data
    - Values of parameters where there are some reasonable prior
  - Two types of things often go wrong
    - Some parameters go to strange values
    - Key moments do not improve or even get worse
    - These are often symptoms of bugs in the code of a flaw in the model (/e.g./ identification problem)
  - Problems in estimation are very frustrating because it can be hard to pin down the source
    - Bug in estimation code
    - Bug in solving the model
    - A flaw in the model
    - OBS: You almost never find the bug by reading the code. Hints:
      - Shut down parts of the model to figure out which part is causing the problem
      - Print out lots of stuff and check if it makes sense


*** Validation

Let's say the parameters of the model have converged to sensible looking values and the in sample fit looks OK

- A good opportunity for validation is when an experiment has been run, and you can estimate the model on the ``control data'' and see if you can forecast the ``treatment data''
- You should think about whether you can validate the model *before* you estimate it
  - Most structural papers do not do much in the way of model validation. One reason is that data needed to do validation is often not easily available

*** Policy Experiments

One of the major reasons we do structural estimation is because we can use structural model to do policy experiments
- Or we may want to use the model to optimize the parameters of a policy to maximize some objective
- Experiments only allow us to see effects of policies that have already been implemented
- A common flaw of structural papers is they do lot of work to solve and estimate the model
  - But when that is done, they do not report any interesting experiments
  - You should have some interesting experiments in mind before you even start

** Conclusion: Why do structural estimation

- One of the reasons is because you are interested in a _model itself_
- Models that we are confident in using for policy evaluation

* Structural modeling workflow

** An example model

To help fix ideas, let's revisit a commonly used model in introductory econometrics:


\begin{align}
\log(w_{i}) =& \beta_0 + \beta_1 s_{i} + \beta_2 x_{i} + \beta_3 x^2_{i} + \varepsilon_{i}
\label{eq:basicmincer}
\end{align}

where we have cross-sectional data and where
- $i$ indexes individuals
- $w_{i}$ is employment income
- $s_{i}$ is years of schooling
- $x_{i}$ is years of work experience (or, more commonly, _potential_ work experience)
- $\varepsilon_{i}$ is anything else that determines income

We want to estimate $\left(\beta_1,\beta_2,\beta_3\right)$, which are *returns to human capital investment*

*** Quick review

- It is nearly certain that eqref:eq:basicmincer suffers from omitted variable bias

    - i.e. there are lots of factors in $\varepsilon_{i}$ that are correlated with both $s_i$ and $w_i$

- Thus, our estimates of $\left(\beta_1,\beta_2,\beta_3\right)$ will not be causal

- We could try to get causal estimates using a variety of identification strategies:

  - find a valid instrument for $s_i$ cite:angristKrueger1991,card1995
  - exploit a discontinuity in $s_i$ cite:ost_al2018
  - randomize $s_i$ cite:attanasio_al2011

*** A structural view of Equation \eqref{eq:basicmincer}

We know that \eqref{eq:basicmincer} will produced biased estimates, but _why_? Some possibilities:

- *ability bias:* $s_i$ and $w_i$ are both positively correlated with unobservable cognitive ability
- *comparative advantage:* multidimensional unobservable ability $\implies$ self-selection into schooling
- *credit constraints:* $s_i$ is a costly investment; some people may not be able to borrow enough
- *preference heterogeneity:* (differing tastes for $s_i$, differing discount rates)

** Theoretical Model Development

- Since schooling has an up-front cost and long-term benefit, need a dynamic model
    - *period 1:* decide how much schooling to get
    - *period 2:* choose whether or not to work; if working, receive income by \eqref{eq:basicmincer}
    - individuals choose schooling level to maximize lifetime utility
- Preferences (denote utility in period $t$ by $u_t$, with $s,x$ and $w$ defined previously)


\begin{align}
u_1\left(z,c,\eta_1\right) & = f\left(z,c,\eta_1\right) \nonumber \\
u_2\left(w\left(s,x\right),k,\eta_2\right) & = g\left(w\left(s,x\right),k,\eta_2\right) \\
\label{eq:utils}
\end{align}

where $z$ is family background, $c$ is schooling costs, $k$ is number of kids in adult household and $\eta_t$ are unobservable preferences [similar to $\varepsilon$ in \eqref{eq:basicmincer}]


With discount factor $\delta \in \left[0,1\right]$, the discounted lifetime utility function is then


\begin{align}
V & = u_1\left(z,c,\eta_1\right) + \delta u_2\left(w\left(s,x\right),k,\eta_2\right)
\label{eq:PDV}
\end{align}

- Equations \eqref{eq:basicmincer}â€“\eqref{eq:PDV} define our model
- A number of important questions arise (But we'll ignore these for today)
    - Where is cognitive ability? What exactly does $c$ represent? Where are loans?
    - Maybe people should care about _consumption_ in period 2, not income
    - Does family background really only enter $u_1$ and not $\log\left(w\right)$?
    - Should $x$ in \eqref{eq:basicmincer} be a function of $s$? (Lower $s \implies$ longer working life)
    - What are people's beliefs about future $k$ when deciding $s$?


*** Overview of the theoretical model

|-----------------------------+--------------------+--------------------+------------------------+---------------------------------|
| *Exog*                      | *Endog*            | *Outcome*          | *Unobs*                | *Parameters*                    |
|-----------------------------+--------------------+--------------------+------------------------+---------------------------------|
| family background $(z)$     | schooling $(s)$    | labor income $(w)$ | income $(\varepsilon)$ | retn. human capital $(\beta)$   |
| schooling costs $(c)$       | period-2 work dec. |                    | preferences $(\eta_t)$ | discount factor $(\delta)$      |
| children in household $(k)$ |                    |                    |                        | other $f(\cdot)$ and $g(\cdot)$ |
|-----------------------------+--------------------+--------------------+------------------------+---------------------------------|



** Practical Specification Issues

Now that we have a model, we need to figure out how to take it to data

- This is where we apply knowledge about _our data_ and _stats/econometrics_
- Key data questions:
    - Can we observe the variables of the model in our data set?
    - If so, are they reliably measured?

- Key specification questions:
    - How to model $\eta_t$ and $\varepsilon$? (Need to make distributional assumptions)
    - Functional forms of $f(\cdot)$ and $g(\cdot)$
    - Should $s$ be continuous (years of schooling) or discrete (college/not)?

What determines the specification is often:

- what is reliably measured in the data
- what is computationally feasible to estimate
    
Parameters of the model either need to be *estimated* or *calibrated*

- e.g. often we don't have reliable data to allow us to estimate $\delta$; we must calibrate it
- Computational feasibility often governs how we specify the different functions

    - e.g. _linear-in-parameters_ with _additively separable_ unobservables [like \eqref{eq:basicmincer}]

* Example real data

Here is some real data from the most recent round of the NLSY97

#+BEGIN_EXAMPLE julia
using CSV, DataFrames, Statistics
df = CSV.read("Data/slides3data.csv"; missingstrings=["NA"])
size(df)
# outputs (6009, 12)
describe(df)
# outputs the below:
12Ã—8 DataFrame
â”‚ Row â”‚ variable       â”‚ mean     â”‚ min  â”‚ median  â”‚ max     â”‚ nunique â”‚ nmissing â”‚
â”‚     â”‚ Symbol         â”‚ Float64  â”‚ Real â”‚ Float64 â”‚ Real    â”‚ Nothing â”‚ Unionâ€¦   â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ id             â”‚ 4534.71  â”‚ 4    â”‚ 4544.0  â”‚ 9022    â”‚         â”‚          â”‚
â”‚ 2   â”‚ female         â”‚ 0.52671  â”‚ 0    â”‚ 1.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 3   â”‚ black          â”‚ 0.269762 â”‚ 0    â”‚ 0.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 4   â”‚ latin          â”‚ 0.210351 â”‚ 0    â”‚ 0.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 5   â”‚ white          â”‚ 0.511067 â”‚ 0    â”‚ 1.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 6   â”‚ employed       â”‚ 0.756532 â”‚ 0    â”‚ 1.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 7   â”‚ wage           â”‚ 25.5309  â”‚ 8.0  â”‚ 20.0    â”‚ 150.0   â”‚         â”‚ 933      â”‚
â”‚ 8   â”‚ collgrad       â”‚ 0.350474 â”‚ 0    â”‚ 0.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 9   â”‚ age            â”‚ 34.967   â”‚ 33   â”‚ 35.0    â”‚ 37      â”‚         â”‚          â”‚
â”‚ 10  â”‚ parent_college â”‚ 0.238975 â”‚ 0    â”‚ 0.0     â”‚ 1       â”‚         â”‚          â”‚
â”‚ 11  â”‚ numkids        â”‚ 1.32684  â”‚ 0    â”‚ 1.0     â”‚ 9       â”‚         â”‚          â”‚
â”‚ 12  â”‚ efc            â”‚ 4.2243   â”‚ 0.0  â”‚ 0.77763 â”‚ 118.111 â”‚         â”‚          â”‚
#+END_EXAMPLE

- We have demographics/background, wages, employment status, education, fertility
- N=6009, age $\in \{33,\ldots,37\}$, and 35% of respondents graduated college

** Setting up the specification

It looks like we can estimate some form of our model

- We have family background, cost of college (this is the =efc= variable)
- We have employment status, wage and number of children
- It looks like we'll have to have $s$ be binary (=collgrad= variable)
- Also need to assume $x = age - 18$ if non-grad, $x = age - 22$ if grad  cite:mincer1974

Then we just need to add some functional form assumptions, and we'll be ready

$\varepsilon \sim$ Normal, $\eta_t \sim$ Logistic

$$u_{i1} = \alpha_0 + \alpha_1 \text{ parent\_college} + \alpha_2 \text{ efc} + \eta_1$$

$$u_{i2} = \gamma_0 + \gamma_1 \mathbb{E} \log w_{i} + \gamma_2 \text{ numkids} + \eta_2$$

** Parameters of the empirical model

We can now detail the parameters of the empirical model

- *wage parameters* $(\beta,\sigma_{\varepsilon})$
  - The latter is the std. dev. of income shocks
- *schooling parameters* $(\alpha)$
- *employment parameters* $(\gamma,\delta)$

Then write down a statistical objective function as a fn. of data and parameters

  - e.g. maximize the likelihood, or minimize the sum of the squared residuals

** Solving and Understanding How the Model Works

Solving the model:

- solve the dynamic utility max problem for given parameter values   
- (we aren't estimating parameter values yet)
    

Understanding the model:

  - simulate data from the model  
  - make sure the simulated data is consistent with the model's implications  
  - look at descriptive statistics from the simulated data

Start with as simple of a model as possible; make sure things are working

- When introducing more complexities, do ``numerical comparative statics''
- Make sure the parameters move in the correct directions
  - e.g. $\uparrow \beta_1 \implies \uparrow$ schooling (ceteris paribus)

** Julia Example                                                   

#+BEGIN_EXAMPLE julia 
N = size(df,1)
beta = [1.65,.4,.06,-.0002]
sigma = .4;
df.exper = df.age .- ( 18*(1 .- df.collgrad) .+ 22*df.collgrad )
df.lwsim = beta[1] .+ beta[2]*df.collgrad .+ beta[3]*df.exper .+ beta[4]*df.exper.^2 .+ sigma*randn(N)
df.lw    = log.(df.wage)
#+END_EXAMPLE


We can then compare how =df.lwsim= compares with =df.lw= in the data

#+BEGIN_EXAMPLE julia
describe(df;cols=[:lw,:lwsim])
# returns
| Row | variable | mean    | min     | median  | max     | nunique | nmissing | eltype                  |
|     | Symbol   | Float64 | Float64 | Float64 | Float64 | Nothing | Union    | Type                    |
---------------------------------------------------------------------------------------------------------
| 1   | lw       | 3.06219 | 2.07944 | 2.99573 | 5.01064 |         | 933      | Union{Missing, Float64} |
| 2   | lwsim    | 2.67169 | 1.12192 | 2.67668 | 3.98557 |         |          | Float64                 |
#+END_EXAMPLE

** Estimation


Most structural models require *nonlinear estimation*

- In nonlinear optimization, starting values are crucial   
  - Initializing at random starting values is likely to give poor results
    - Keane recommends calibrating the model by hand
    - e.g. match the intercept of each equation to the $\overline{Y}$'s in the data
  - I recommend estimating an intercepts-only model (or with very few $X$'s)
    - But this advice is model-specific!

*** Example using real data

In our simple model, we can get good starting values by estimating OLS and logits
- The wage equation can be estimated by OLS (on the subsample who are employed)

#+BEGIN_EXAMPLE julia
using GLM
\hat\beta= lm(@formula(lw ~ collgrad + exper + exper^2), df[df.employed.==1,:])
# returns
Coefficients:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
               Estimate  Std. Error    t value  Pr(>|t|)    Lower 95%   Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(Intercept)   2.94607    0.323145     9.11688     <1e-18   2.31255     3.57959
collgrad      0.534326   0.0271395   19.6881      <1e-82   0.481119    0.587532
exper        -0.0265561  0.0412115   -0.644386    0.5194  -0.107351    0.0542385
exper ^ 2     0.0014304  0.00132307   1.08112     0.2797  -0.00116346  0.00402426
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df.elwage = predict(\hat\beta, df) # generates expected log wage for all observations
r2(\hat\beta)                               # reports R2
sqrt(deviance(\hat\beta)/dof_residual(\hat\beta))  # reports root mean squared error
#+END_EXAMPLE


The $u_t$ equations can be estimated as simple logits (on the full sample)

#+BEGIN_EXAMPLE julia
\hat\alpha = glm(@formula(collgrad ~ parent_college + efc), df, Binomial(), LogitLink())
# returns
Coefficients:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                  Estimate  Std. Error   z value  Pr(>|z|)   Lower 95%   Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(Intercept)     -1.20091    0.0364888   -32.9118    <1e-99  -1.27243    -1.1294
parent_college   1.47866    0.068433     21.6074    <1e-99   1.34453     1.61278
efc              0.0450253  0.00437704   10.2867    <1e-24   0.0364464   0.0536041
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\hat\gamma= glm(@formula(employed ~ elwage + numkids), df, Binomial(), LogitLink())
# returns
Coefficients:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
               Estimate  Std. Error   z value  Pr(>|z|)  Lower 95%   Upper 95%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(Intercept)  -4.25036     0.454826   -9.34503    <1e-20  -5.1418    -3.35892
elwage        1.80081     0.149078   12.0796     <1e-32   1.50863    2.093
numkids      -0.0797204   0.0218106  -3.65512    0.0003  -0.122468  -0.0369724
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#+END_EXAMPLE

*** Do these results make sense?

- It can be informative to try and interpret even these simple results

- wage equation:
    - insignificant return to experience is surprising; otherwise makes sense
- schooling choice:
    - If =efc= captures college costs, it should have a negative sign
    - This suggests omitted variable bias in this equation
- employment choice:
    - These results check out; may want to introduce nonlinearities in =numkids=

* Validation

If you have a good model, it should be *valid* (i.e. predict well out of sample)

- Validation is not always possible, but it's good to do if you can

  - e.g. if experimental data, estimate on control group, validate on treatment group
  - e.g. see if model can replicate major policy change in data

- More simply, you could throw out half your data, then try to predict other half
    - This is typically not done if the full sample isn't huge

* Policy Experiments

- This is the main reason to do structural estimation!
- Structural estimation $\implies$ recovering the DGP of the model
- Once we know the DGP, we can simulate data from it and do policy experiments
    - requires having policy-invariant parameters!
- We can predict the effects of:
    - proposed policies
    - hypothetical policies    
- Contrast with RCTs, which only reveal effects of implemented policies


** Example using real data

- We have two policy variables we could play with

    1. =efc= (i.e. how much gov't subsidizes college tuition & fees)
    2. return to schooling (this could change due to e.g. technological change)

- Here's how we would look at a counterfactual with lower cost:
#+BEGIN_EXAMPLE julia
df_cfl     = deepcopy(df)
df_cfl.efc = df.efc .- 1         # change value of efc to be $1,000 less
df.basesch = predict(\hat\alpha, df)     # predicted collgrad probabilities under status quo
df.cflsch  = predict(\hat\alpha, df_cfl) # predicted collgrad probabilities under counterfactual
describe(df;cols=[:basesch,:cflsch])
# returns
â”‚ Row â”‚ variable â”‚ mean     â”‚ min      â”‚ median   â”‚ max      â”‚ nunique â”‚ nmissing â”‚
â”‚     â”‚ Symbol   â”‚ Float64  â”‚ Float64  â”‚ Float64  â”‚ Float64  â”‚ Nothing â”‚ Int64    â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1   â”‚ basesch  â”‚ 0.350474 â”‚ 0.231313 â”‚ 0.24387  â”‚ 0.986715 â”‚         â”‚ 0        â”‚
â”‚ 2   â”‚ cflsch   â”‚ 0.341794 â”‚ 0.223404 â”‚ 0.235663 â”‚ 0.986111 â”‚         â”‚ 0        â”‚
#+END_EXAMPLE

Average likelihood of =collgrad= _declines_ from 35% to 34.2%

- This doesn't make sense because the =efc= coefficient didn't make sense
- We can't assess the counterfactual of increasing the return to schooling
- Because =elwage= doesn't directly enter the =collgrad= logit model
- This is because we aren't really estimating the dynamic model yet



* Conclusions

** In summary: Why structural estimation?

- Want to examine effects of policies not yet implemented
- Learn more about economics by looking through the lens of a model
- Assess performance of theoretical models in explaining real-world data
- Can be used to build up long-run ``canonical'' models of behavior in many areas
- It can be really fun to do more complicated econometrics beyond simple regressions
- Observational data is much cheaper to collect than experimental data


** In summary: Why _not_ structural estimation?

- It's really difficult to write down and estimate a tractable, realistic model!
- It requires additional effort beyond data preparation and running regressions
- Understanding identification of the model takes a lot of effort, too
- It can be really miserable to try and debug the code of a structural estimation
- Many structural models can take weeks to estimate one specification
    - in addition to months spent coding/debugging beforehand
- As you can see, even with a simple model things have already gotten complicated!
