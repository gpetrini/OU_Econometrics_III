% Created 2020-08-27 qui 15:55
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[theorems, skins]{tcolorbox}
\usepackage[style=abnt,noslsn,extrayear,uniquename=init,giveninits,justify,sccite,
scbib,repeattitles,doi=false,isbn=false,url=false,maxcitenames=2,
natbib=true,backend=biber]{biblatex}
\usepackage{url}
\usepackage[linktocpage,pdfstartview=FitH,colorlinks,
linkcolor=blue,anchorcolor=blue,
citecolor=blue,filecolor=blue,menucolor=blue,urlcolor=blue]{hyperref}
\usepackage{attachfile}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{minted}
\bibliography{References.bib}
\author{Gabriel Petrini}
\date{August 25th, 2020}
\title{Introduction to Structural Models}
\begin{document}

\maketitle
\tableofcontents



\section{Introduction}
\label{sec:org7a0c69c}


\textbf{Pre-class reading:} 

\begin{itemize}
\item \fullcite{lewbel2019zoo}
\end{itemize}

\subsection{Reading Quiz}
\label{sec:org91f3d7b}

\begin{enumerate}
\item Explain what identification means, according to Arthur Lewbel

\item Correctly order the following econometric actions in their logical sequence:
\begin{itemize}
\item estimation
\item hypothesis testing
\item identification
\item inference
\end{itemize}

\item What are the two characteristics of reduced-form causal methods, according to Lewbel? How is this different from structural methods?
\end{enumerate}


\begin{enumerate}
\item What does Lewbel refer to as ``crude structural modeling''?

\item What does Lewbel suggest is a way to overcome the external validity problem?
\end{enumerate}


\subsection{Causality: the goal of econometrics}
\label{sec:orgafdb3fa}

In any econometric endeavor, the goal is to uncover causal relationships. Correlations, otherwise, is contaminated by omitted variable bias.

\subsubsection{Causality requires a counterfactual}
\label{sec:org0dc1be3}

Causality is defined in terms of a \textbf{counterfactual}

\begin{itemize}
\item this is the notion of \uline{ceteris paribus} in principles of economics
\end{itemize}

\textbf{``Causal effect'':} difference between reality and the most plausible counterfactual

\subsection{Structural empirical work}
\label{sec:org430ac96}

\textbf{Structure:} A structure is a data generating process, i.e. a set of functional or probabilistic relationships between observable and latent variables which implies a joint distribution of the observables

\begin{itemize}
\item The goal of structural estimation, then, is to estimate the parameters of the DGP
\item This allows us to make counterfactual comparisons, i.e. perform causal inference

\item Note that ``structural'' here refers to basically all of modern econometrics
\end{itemize}

Estimate parameters of a \uline{data generating process} (DGP) which are assumed to be invariant to policy changes or other counterfactuals

\begin{itemize}
\item Once we know the DGP, we can make causal inferences
\item \emph{e.g.} estimate a DGP that specifies how cognitive ability and family background relate to the decision to enroll in college and to post-graduation earnings
\end{itemize}


\subsubsection{Brief history of the term ``reduced form''}
\label{sec:org9cfa240}

\begin{itemize}
\item The term \uline{reduced form} refers to solving a structural model
\begin{itemize}
\item The structural model may have endogenous variables on both sides of the equation
\item But the reduced form puts all endogenous variables on the left hand side
\item All exogenous variables and error terms are on the right hand side
\end{itemize}
\item Reduced form tends to refer to linear models estimated by RCT, IV, DID, RDD, etc.
\begin{itemize}
\item Methods that try to exploit randomization (or quasi-randomization)
\item Synonymous with the phrase ``identification strategy''
\end{itemize}
\item \uline{Structural} tends to refer to \textbf{non-linear} models that are more difficult to estimate
\begin{itemize}
\item Methods that make explicit the (typically large) set of maintained assumptions
\item Methods that focus on settings where RCTs would be infeasible
\item Very little randomization is involved
\end{itemize}
\end{itemize}

\section{Randomize Control-Trial (RCT) as structural estimation}
\label{sec:org3317d19}

\begin{itemize}
\item All causal inference is structural in nature (as correctly defined)
\item An RCT is a structural model that can be evaluated \uline{descriptively} 
\begin{itemize}
\item No fancy econometrics needed: just compute \(\overline{y}_{\text{Treatment}} - \overline{y}_{\text{Control}}\)
\end{itemize}
\item This is because great effort was expended at the randomization step
\item The experimenters had a (structural) model in mind when defining treatment
\end{itemize}

\subsection{Not every DGP can be evaluated by RCT}
\label{sec:orgc055deb}

\begin{itemize}
\item Without randomization, we have to rely on observational data
\item This requires more complex econometric methods to estimate the DGP
\begin{itemize}
\item Need to explicitly specify how unobservables relate to other parts of model
\item \emph{e.g.} can't randomize a merger of two large firms, or a person's height
\end{itemize}
\end{itemize}

$$
\log \text{wages} = \beta_0 + \beta_1 \text{educ} + \underbrace{\varepsilon}_{\text{familly background, genetics}}
$$

\section{Key parameters of any economic model}
\label{sec:orgf0c891f}

\begin{itemize}
\item As mentioned above, we assume that DGP parameters are \uline{policy-invariant}
\item These parameters tend to be related to \textbf{economic fundamentals}:

\begin{itemize}
\item commodities
\item demographics
\item preferences
\item production technology
\item information and expectations
\item space (includes networks \& social interactions)
\end{itemize}
\end{itemize}

\section{Reading-to-Children Example}
\label{sec:orgd927c46}

\subsection{Reduced-form example}
\label{sec:org848d374}

\begin{itemize}
\item A \uline{reduced-form} (as misused today) approach would look like the following:

\begin{enumerate}
\item recruit a group of families to participate in a reading study
\item randomize into ``no-read'' and ``read'' groups
\item after some period of time, give their children a cognitive test
\item compare the average scores of children across each of the groups
\end{enumerate}
\end{itemize}


\subsection{Structural approach}
\label{sec:orgdfe4df1}

\begin{itemize}
\item A \uline{structural} (as misused today) approach would look like the following:

\begin{enumerate}
\item write a model of child skill formation \cite{cunha_al2010}
\item gather data on parental and child time use and child test scores
\item estimate the parameters of the child skill formation model
\item use model to simulate counterfactual policies (e.g. where reading is set to 0)
\item compare average scores in counterfactual and \emph{status quo}
\end{enumerate}
\end{itemize}

\subsection{Hybrid approach}
\label{sec:orgffe791e}

\begin{itemize}
\item A \uline{hybrid} approach would do the following:

\begin{enumerate}
\item estimate the skill formation parameters
\item leverage randomization to better estimate/validate the model
\begin{itemize}
\item e.g. by allowing for identification of a parameter previously not identifiable
\item e.g. recover randomization-implied ATE using structural parameter estimates
\end{itemize}
\item use the validated structural model to explore other counterfactuals
\end{enumerate}
\end{itemize}

\section{What is identification? \cite{lewbel2019zoo}}
\label{sec:org81841e2}

\begin{itemize}
\item \textbf{Identification:} model parameters being \uline{uniquely determined} from the \uline{observable population} that generates the data
\begin{itemize}
\item identification is never a question about a sample of data
\begin{itemize}
\item it is a question about the population from which the sample is drawn
\end{itemize}
\end{itemize}
\end{itemize}

\subsection{More formal definition}
\label{sec:org52206bc}


Let \(\theta\) denote a set of unknown parameters that we would like to learn about, and ideally, estimate

\begin{itemize}
\item e.g. regressor coefficients, average treatment effects, or error distributions
\item identification asks what could be learned about parameters \(\theta\) from observable data
\item if we knew the population that data are drawn from, would \(\theta\) be known?
\item if not, what could be learned about \(\theta\)?
\end{itemize}

\subsection{Why is identification important?}
\label{sec:org0129c47}

\begin{itemize}
\item The study of identification logically precedes estimation, inference, and testing
\item For \(\theta\) to be identified, alternative values of \(\theta\) must imply different distributions of the observable data
\item If \(\theta\) is not identified, then we cannot hope to find a consistent estimator for \(\theta\)
\item More generally, identification failures complicate statistical analyses of models, so recognizing lack of identification, and searching for restrictions that suffice to attain identification, are fundamentally important problems in econometric modeling
\begin{itemize}
\item If the DGP is not known, it is not possible to do hypothesis test (inference)
\end{itemize}
\end{itemize}

\subsection{Reduced-form vs. Structural Identification}
\label{sec:org51e27c1}

\begin{itemize}
\item In \uline{reduced-form} econometrics (a.k.a. causal modeling):
\begin{itemize}
\item Typically talk of an ``identification strategy'' (i.e. randomization setup)
\item Focus is on estimation of treatment effects, not ``deep parameters''
\item Relies on randomization from some kind of randomized or natural experiment
\end{itemize}

\item In \uline{structural econometrics}:

\begin{itemize}
\item Typically talk of ``establishing identification'' (i.e. sufficient variation in data)
\item In complex models, can be difficult to do without imposing more assumptions
\end{itemize}
\end{itemize}

\subsection{The Credibility Revolution}
\label{sec:org02144d4}

\begin{itemize}
\item What makes an identification strategy credible?
\begin{itemize}
\item Identification means separating selection from treatment
\item This is best done when treatment is randomized
\item The closer a reduced-form model is to an RCT, the better
\end{itemize}
\end{itemize}

\subsubsection{Examples of Identification Strategies}
\label{sec:orgf0e9dc6}

\begin{itemize}
\item Randomized experiments, field experiments, lab experiments
\item Instrumental variables, regression discontinuity
\item Difference in differences, synthetic control methods
\item Matching methods (nearest neighbor, propensity score, \ldots{})
\item OLS that does not suffer from omitted variable bias
\item These are almost exclusively estimated using linear econometric models
\item Credibility is proportional to the \textbf{``cleanliness'' of randomization}
\end{itemize}

\subsubsection{Credible Structural Models}
\label{sec:org21c1088}

What makes a structural model credible?

\begin{itemize}
\item At the very least, the model should ``fit the data'' (i.e. reproduce key patterns)
\item But that is usually a low bar to clear, so additional criteria are required
\item Results should also ``make sense'' (i.e. conform to economic theory)
\begin{itemize}
\item e.g. An upward-sloping demand curve would violate this criterion
\end{itemize}
\item Typically requires modeling heterogeneity in preferences or productivity
\begin{itemize}
\item Another difficulty: separating preferences from constraints
\end{itemize}
\end{itemize}

\subsubsection{Structural Methods}
\label{sec:orgdbfd343}

Unlike reduced-form methods, there is not a set ``toolkit'' of techniques

\begin{itemize}
\item Rather, structural modeling is a bit \uline{ad hoc} or a bit ``Wild West''

\item Whereas RF methods almost exclusively focus on linear econometric models, Structural methods overwhelmingly require use of \textbf{non-linear} econometric models
\begin{itemize}
\item Structural models are typically estimated by GMM or Maximum Likelihood
\item Computational know-how helps speed up the process of estimating these models
\end{itemize}
\end{itemize}


\section{Internal and External Validity}
\label{sec:org96075f9}

\begin{itemize}
\item \textbf{Internal validity} refers to ``how causal'' an estimated parameter is
\begin{itemize}
\item ``This approach is internally valid'' \(\Rightarrow\) no selection bias
\end{itemize}

\item \textbf{External validity} refers to generalizability of estimates to new contexts
\item Typically, RF approaches are very good at internal validity but not at external validity
\begin{itemize}
\item On the other hand, if economic agents behave similarly across contexts, structural models can be externally valid
\item RF and structural methods used together can improve both internal and external validity
\end{itemize}
\end{itemize}


\subsection{Example: Internal vs. External Validity}
\label{sec:org7c60958}

Suppose we want to measure earth's gravitational force, \(g\)

\begin{itemize}
\item We can measure \(g\) by timing how long it takes various objects to fall some distance
\item We can do this with objects of varying mass and of varying fall distances
\begin{itemize}
\item Using this data, we can estimate earth's \(g\)
\end{itemize}
\item But what about the \(g\) on Mars? Or some other planet?
\item For this we need a model of what exactly determines \(g\)
\begin{itemize}
\item (A planet's mass and proximity to other large objects)
\end{itemize}
\item This model will tell us what \(g\) is on planets we haven't yet visited
\end{itemize}
\end{document}
