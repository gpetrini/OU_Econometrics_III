#+TITLE: Preference Heterogeneity with Mixture Distributions
#+AUTHOR: Gabriel Petrini
#+DATE: date
#+LATEX_HEADER: \usepackage[american]{babel}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \bibliography{References.bib}
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>

#+HTML_HEAD: <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
#+HTML_HEAD: <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>

* Reading Quiz

1. Explain why mixed logit is such a popular model, according to Train. What are its strong points vis-Ã -vis the IIA problem?
2. What are the computational drawbacks to mixed logit?
3. What are two names for a mixed logit model that has a discrete mixing distribution? 
4. Explain why the EM algorithm is a potentially powerful tool for estimating discrete choice models.
5. How does the EM algorithm work? Why does it work?

* Preference Heterogeneity

So far, we have only looked at models where all agents have _identical preferences_

- Mathematically, $\beta_{RedBus}$ does not vary across agents
    - Implies everyone has same price elasticity, etc.
- Failure to account for this heterogeneity will result in a misleading model

** Observable preference heterogeneity

One solution to the homogeneity problem is to add interaction terms

- Suppose we have a 2-option transportation model:
\begin{align*}
u_{i,bus}&=\beta_1 X_i + \gamma Z_1\\
u_{i,car}&=\beta_2 X_i + \gamma Z_2
\end{align*}

- We could introduce heterogeneity in $\gamma$ by interacting $Z_j$ with $X_i$:
\begin{align*}
u_{i,bus}&=\beta_1 X_i + \widetilde{\gamma} Z_1 X_i\\
u_{i,car}&=\beta_2 X_i + \widetilde{\gamma} Z_2 X_i
\end{align*}

- Now a change in $Z_j$ will have a heterogeneous impact on utility depending on $X_i$
  - e.g. those w/diff. income $(X_i)$ may be more/less sensitive to changes in price $(Z_j)$

** Unobservable preference heterogeneity

Many dimensions of preferences are likely unobserved. In this case, we need to ``interact'' $Z$ with something unobserved

- One way to do this is to assume that $\beta$ or $\gamma$ varies across people
- Assume some distribution (e.g. Normal), called the *mixing distribution*
- Then integrate this out of the likelihood function

~What does the integration means in this case?~

* Mixed Logit likelihood function

Assume, e.g. $\gamma_i \sim F$ with pdf $f$ and distributional parameters $\mu$ and $\sigma$

- Then the logit choice probabilities become
\begin{align*}
P_{ij}\left(X,Z;\beta,\gamma\right)&= \int\frac{\exp\left(X_{i}\left(\beta_{j}-\beta_{J}\right)+\gamma\left(Z_{ij}-Z_{iJ}\right)\right)}{\sum_k \exp\left(X_{i}\left(\beta_{k}-\beta_{J}\right)+\gamma\left(Z_{ik}-Z_{iJ}\right)\right)}f\left(\gamma;\mu,\sigma\right)d\gamma
\end{align*}

- Annoyance: the log likelihood now has an integral inside the log!
\begin{align*}
\ell\left(X,Z;\beta,\gamma,\mu,\sigma\right)&=\sum_{i=1}^N \log\left\{\int\prod_{j}\left[\frac{\exp\left(X_{i}\left(\beta_{j}-\beta_{J}\right)+\gamma\left(Z_{ij}-Z_{iJ}\right)\right)}{\sum_k \exp\left(X_{i}\left(\beta_{k}-\beta_{J}\right)+\gamma\left(Z_{ik}-Z_{iJ}\right)\right)}\right]^{d_{ij}}f\left(\gamma;\mu,\sigma\right)d\gamma\right\}
\end{align*}

** Common mixing distributions

- Normal
- Log-normal
- Uniform
- Triangular
- Can also go crazy and specify a multivariate normal
  - This would allow, e.g. heterogeneity in $\gamma$ to be correlated with $\beta$

** Mixed Logit estimation

With the integral inside the log, estimation of the mixed logit is intensive. To estimate the likelihood function, need to numerically approximate the integral

- The most common way of doing this is *quadrature*
- Another common way of doing this is by *simulation* (Monte Carlo integration)


** Finite Mixture Distributions

Another option to mixed logit is to assume the mixing distribution is _discrete_. We assume we have missing variable that has finite support and is independent from the other variables 

~What does `finite support' means?~

- Let $\pi_s$ denote the probability of being in the $s$th unobserved group
- Integrating out over the unobserved groups then yields the following log likelihood:
\begin{align*}
\ell\left(X,Z;\beta,\gamma,\pi\right)=&\sum_{i=1}^N \log\left\{\sum_{s}\prod_{j}\left[\frac{\exp\left(X_{i}\left(\beta_{j}-\beta_{J}\right)+\gamma_{s}\left(Z_{ij}-Z_{iJ}\right)\right)}{\sum_k \exp\left(X_{i}\left(\beta_{k}-\beta_{J}\right)+\gamma_{s}\left(Z_{ik}-Z_{iJ}\right)\right)}\right]^{d_{ij}}\right\}\\
\end{align*}

** Mixture Distributions and Panel Data

With panel data, mixture dist. allows for *permanent unobserved heterogeneity*

- Here the unobs. variable is fixed over time and indep. of the covariates at $t=1$
- The log likelihood function for the finite mixture case is then:
\begin{align*}
\ell\left(X,Z;\beta,\gamma,\pi\right)=&\sum_{i=1}^N \log\left\{\sum_{s}\prod_{t}\prod_{j}\left[\frac{\exp\left(X_{it}\left(\beta_{j}-\beta_{J}\right)+\gamma_{s}\left(Z_{ijt}-Z_{iJt}\right)\right)}{\sum_k \exp\left(X_{it}\left(\beta_{k}-\beta_{J}\right)+\gamma_{s}\left(Z_{ikt}-Z_{iJt}\right)\right)}\right]^{d_{ijt}}\right\}
\end{align*}

- And for the mixed logit case is:
\begin{align*}
\ell\left(X,Z;\beta,\gamma,\mu,\sigma\right)=&\sum_{i=1}^N \log\left\{\int\prod_{t}\prod_{j}\left[\frac{\exp\left(X_{it}\left(\beta_{j}-\beta_{J}\right)+\gamma\left(Z_{ijt}-Z_{iJt}\right)\right)}{\sum_k \exp\left(X_{it}\left(\beta_{k}-\beta_{J}\right)+\gamma\left(Z_{ikt}-Z_{iJt}\right)\right)}\right]^{d_{ijt}}f\left(\gamma;\mu,\sigma\right)d\gamma\right\}\\
\end{align*}

* Dynamic Selection

Often, we want to link the choices to other outcomes:
- labor force participation and earnings
- market entry and profits

If individuals choose to participate in the labor market based upon unobserved wages, our estimates of the returns to participating will be biased  

- Mixture distributions provide an alternative way of controlling for selection
- *Assumption:* no selection problem once we control for the unobserved variable

Let $Y_{1t}$ denote the choice and $Y_{2t}$ denote the outcome

-  The previous assumption means the joint likelihood is separable:
\begin{align*}
\mathcal{L}(Y_{1t},Y_{2t}|X_{1t},X_{2t},\alpha_1,\alpha_2,s)&=\mathcal{L}(Y_{1t}|Y_{2t},X_{1t},\alpha_1,s)\mathcal{L}(Y_{2t}|X_{2t},\alpha_2,s)\\
&=\mathcal{L}(Y_{1t}|X_{1t},\alpha_1,s)\mathcal{L}(Y_{2t}|X_{2t},\alpha_2,s)
\end{align*}
where $s$ is the unobserved type

** Estimation in Stages

Suppose $s$ was observed. There'd be no selection problem as long as we could condition on $s$ and $X_{1t}$. The log likelihood function is:
\begin{align*}
\ell=&\sum_{i}\sum_t \ell_1(Y_{1t}|X_{1t},\alpha_1,s)+\ell_2(Y_{2t}|X_{2t},\alpha_2,s)
\end{align*}

Estimation could proceed in stages:

1. Estimate $\alpha_2$ using only $\ell_2$
2. Taking the estimate of $\alpha_2$ as given, estimate $\alpha_1$ using $\ell_1$

*** Non-separable means no stages

When $s$ is unobserved, however, the log likelihood function is not additively separable:
\begin{align*}
\ell=&\sum_i\log\left(\sum_s\pi_s\prod_t\mathcal{L}(Y_{1t}|X_{1t},\alpha_1,s)\mathcal{L}(Y_{2t}|X_{2t},\alpha_2,s)\right)
\end{align*}
where $\mathcal{L}$ is a likelihood function

- Makes sense: if there is a selection problem, we can't estimate one part of the problem without considering what is happening in the other part

** The EM Algorithm

We can get additive separability of the finite mixture model with the *EM algorithm* (``Expectation-Maximization''). The algorithm iterates on two steps:
- *E-step:* estimate parameters having to do with the mixing distribution (i.e. the $\pi$'s)
- *M-step:* pretend you observe the unobserved variable and estimate

The EM algorithm is used in other applications to fill in missing data
- In this case, the missing data is the permanent unobserved heterogeneity

With the EM algorithm, the non-separable likelihood function
\begin{align*}
\ell=&\sum_i\log\left(\sum_s\pi_s\prod_t\mathcal{L}(Y_{1t}|X_{1t},\alpha_1,s)\mathcal{L}(Y_{2t}|X_{2t},\alpha_2,s)\right)
\end{align*}
can be written in a form that is separable:
\begin{align*}
\ell=&\sum_i\sum_s q_{is}\sum_t\ell_1\left(Y_{1t}|X_{1t},\alpha_1,s\right)+\ell_2\left(Y_{2t}|X_{2t},\alpha_2,s)\right)
\end{align*}
where $q_{is}$ is the probability that $i$ belongs to group $s$

- $q_{is}$ satisfies $\pi_s = \frac{1}{N}\sum_{i}q_{is}$

*** Estimation in stages again

We can now estimate the model in stages because of the restoration of separability. The only twist is that we need to *weight* by the $q$'s in each estimation stage

- Stage 1 of M-step: estimate $\ell(Y_{1t}|X_{1t},\alpha_1,s)$ weighting by the $q$'s
- Stage 2 of M-step: estimate $\ell(Y_{2t}|X_{1t},\alpha_1,s)$ weighting by the $q$'s
- E-step: update the $q$'s by calculating
\begin{align*}
q_{is}=&\frac{\pi_s\prod_t\mathcal{L}(Y_{1t}|X_{1t},\alpha_1,s)\mathcal{L}(Y_{2t}|X_{2t},\alpha_2,s)}{\sum_m\pi_m\prod_t\mathcal{L}(Y_{1t}|X_{1t},\alpha_1,m)\mathcal{L}(Y_{2t}|X_{2t},\alpha_2,m)}
\end{align*}
- Iterate on E and M steps until the $q$'s converge cite:arcidiaconoJones2002

* To Recap

Why are we doing all of this difficult work?

- Because preference heterogeneity allows for a more credible structural model
- Introducing preference heterogeneity can make the model intractible
- Discretizing the distribution of heterogeneity and using the EM algorithm can help
